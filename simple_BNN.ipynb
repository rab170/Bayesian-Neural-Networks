{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Dense\n",
    "\n",
    "from imutils import paths\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import pymc3 as pm\n",
    "\n",
    "from edward.models import Bernoulli, Normal\n",
    "import edward as ed\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_feature_vector(image, size=(32, 32)): return cv2.resize(image, size).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = map(image_to_feature_vector, [cv2.imread(cat) for cat in glob.glob('data/cats/*')])\n",
    "dogs = map(image_to_feature_vector, [cv2.imread(dog) for dog in glob.glob('data/dogs/*')])\n",
    "\n",
    "data = np.vstack((cats,dogs))\n",
    "labels = ['cat']*len(cats) + ['dog']*len(dogs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(labels)\n",
    "data = np.array(data) / 255.0\n",
    "labels = np_utils.to_categorical(labels, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainData, testData, trainLabels, testLabels) = train_test_split(data, labels, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kbrusch/Desktop/_notebook/lib/python2.7/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(768, activation=\"relu\", kernel_initializer=\"uniform\", input_dim=3072)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/kbrusch/Desktop/_notebook/lib/python2.7/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(384, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(768, input_dim=3072, init=\"uniform\",\n",
    "\tactivation=\"relu\"))\n",
    "model.add(Dense(384, init=\"uniform\", activation=\"relu\"))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kbrusch/Desktop/_notebook/lib/python2.7/site-packages/keras/models.py:837: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "300/300 [==============================] - 0s - loss: 0.7087 - acc: 0.5300     \n",
      "Epoch 2/50\n",
      "300/300 [==============================] - 0s - loss: 0.6989 - acc: 0.5167     \n",
      "Epoch 3/50\n",
      "300/300 [==============================] - 0s - loss: 0.6636 - acc: 0.5933     \n",
      "Epoch 4/50\n",
      "300/300 [==============================] - 0s - loss: 0.6651 - acc: 0.6233     \n",
      "Epoch 5/50\n",
      "300/300 [==============================] - 0s - loss: 0.6483 - acc: 0.6333     \n",
      "Epoch 6/50\n",
      "300/300 [==============================] - 0s - loss: 0.6798 - acc: 0.5567     \n",
      "Epoch 7/50\n",
      "300/300 [==============================] - 0s - loss: 0.6930 - acc: 0.6067     \n",
      "Epoch 8/50\n",
      "300/300 [==============================] - 0s - loss: 0.6275 - acc: 0.6900     \n",
      "Epoch 9/50\n",
      "300/300 [==============================] - 0s - loss: 0.6320 - acc: 0.6667     \n",
      "Epoch 10/50\n",
      "300/300 [==============================] - 0s - loss: 0.6167 - acc: 0.7033     \n",
      "Epoch 11/50\n",
      "300/300 [==============================] - 0s - loss: 0.6099 - acc: 0.7067     \n",
      "Epoch 12/50\n",
      "300/300 [==============================] - 0s - loss: 0.6046 - acc: 0.7233     \n",
      "Epoch 13/50\n",
      "300/300 [==============================] - 0s - loss: 0.6066 - acc: 0.7133     \n",
      "Epoch 14/50\n",
      "300/300 [==============================] - 0s - loss: 0.5909 - acc: 0.7267     \n",
      "Epoch 15/50\n",
      "300/300 [==============================] - 0s - loss: 0.7111 - acc: 0.5567     \n",
      "Epoch 16/50\n",
      "300/300 [==============================] - 0s - loss: 0.6380 - acc: 0.6233     \n",
      "Epoch 17/50\n",
      "300/300 [==============================] - 0s - loss: 0.5817 - acc: 0.7467     \n",
      "Epoch 18/50\n",
      "300/300 [==============================] - 0s - loss: 0.5758 - acc: 0.7433     \n",
      "Epoch 19/50\n",
      "300/300 [==============================] - 0s - loss: 0.5907 - acc: 0.7367     \n",
      "Epoch 20/50\n",
      "300/300 [==============================] - 0s - loss: 0.5809 - acc: 0.7200     \n",
      "Epoch 21/50\n",
      "300/300 [==============================] - 0s - loss: 0.5720 - acc: 0.7633     \n",
      "Epoch 22/50\n",
      "300/300 [==============================] - 0s - loss: 0.5595 - acc: 0.7933     \n",
      "Epoch 23/50\n",
      "300/300 [==============================] - 0s - loss: 0.5535 - acc: 0.7567     \n",
      "Epoch 24/50\n",
      "300/300 [==============================] - 0s - loss: 0.5552 - acc: 0.7367     \n",
      "Epoch 25/50\n",
      "300/300 [==============================] - 0s - loss: 0.6020 - acc: 0.6700     \n",
      "Epoch 26/50\n",
      "300/300 [==============================] - 0s - loss: 0.5424 - acc: 0.7433     \n",
      "Epoch 27/50\n",
      "300/300 [==============================] - 0s - loss: 0.5391 - acc: 0.8100     \n",
      "Epoch 28/50\n",
      "300/300 [==============================] - 0s - loss: 0.5326 - acc: 0.7767     \n",
      "Epoch 29/50\n",
      "300/300 [==============================] - 0s - loss: 0.5377 - acc: 0.7967     \n",
      "Epoch 30/50\n",
      "300/300 [==============================] - 0s - loss: 0.5962 - acc: 0.6467     \n",
      "Epoch 31/50\n",
      "300/300 [==============================] - 0s - loss: 0.5734 - acc: 0.6700     \n",
      "Epoch 32/50\n",
      "300/300 [==============================] - 0s - loss: 0.5168 - acc: 0.8567     \n",
      "Epoch 33/50\n",
      "300/300 [==============================] - 0s - loss: 0.5518 - acc: 0.6900     \n",
      "Epoch 34/50\n",
      "300/300 [==============================] - 0s - loss: 0.5113 - acc: 0.8267     \n",
      "Epoch 35/50\n",
      "300/300 [==============================] - 0s - loss: 0.5252 - acc: 0.7433     \n",
      "Epoch 36/50\n",
      "300/300 [==============================] - 0s - loss: 0.5153 - acc: 0.7733     \n",
      "Epoch 37/50\n",
      "300/300 [==============================] - 0s - loss: 0.5120 - acc: 0.7933     \n",
      "Epoch 38/50\n",
      "300/300 [==============================] - 0s - loss: 0.4942 - acc: 0.8400     \n",
      "Epoch 39/50\n",
      "300/300 [==============================] - 0s - loss: 0.4933 - acc: 0.8433     \n",
      "Epoch 40/50\n",
      "300/300 [==============================] - 0s - loss: 0.5132 - acc: 0.7833     \n",
      "Epoch 41/50\n",
      "300/300 [==============================] - 0s - loss: 0.4840 - acc: 0.8533     \n",
      "Epoch 42/50\n",
      "300/300 [==============================] - 0s - loss: 0.5069 - acc: 0.7800     \n",
      "Epoch 43/50\n",
      "300/300 [==============================] - 0s - loss: 0.4966 - acc: 0.7733     \n",
      "Epoch 44/50\n",
      "300/300 [==============================] - 0s - loss: 0.4811 - acc: 0.8333     \n",
      "Epoch 45/50\n",
      "300/300 [==============================] - 0s - loss: 0.4866 - acc: 0.8233     \n",
      "Epoch 46/50\n",
      "300/300 [==============================] - 0s - loss: 0.4765 - acc: 0.8367     \n",
      "Epoch 47/50\n",
      "300/300 [==============================] - 0s - loss: 0.4849 - acc: 0.7800     \n",
      "Epoch 48/50\n",
      "300/300 [==============================] - 0s - loss: 0.4677 - acc: 0.8333     \n",
      "Epoch 49/50\n",
      "300/300 [==============================] - 0s - loss: 0.4952 - acc: 0.7833     \n",
      "Epoch 50/50\n",
      "300/300 [==============================] - 0s - loss: 0.4662 - acc: 0.8033     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1142cda10>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"[INFO] compiling model...\")\n",
    "sgd = SGD(lr=0.01)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=sgd, metrics=[\"accuracy\"])\n",
    "model.fit(trainData, trainLabels, nb_epoch=50, batch_size=128, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] evaluating on testing set...\")\n",
    "(loss, accuracy) = model.evaluate(testData, testLabels, batch_size=128, verbose=1)\n",
    "print(\"[INFO] loss={:.4f}, accuracy: {:.4f}%\".format(loss, accuracy*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 3072)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(trainData, testData, trainLabels, testLabels) = train_test_split(data, labels, test_size=0.25, random_state=42)\n",
    "\n",
    "trainData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = Sequential()\n",
    "#model.add(Dense(768, input_dim=3072, init=\"uniform\",\n",
    "#\tactivation=\"relu\"))\n",
    "#model.add(Dense(384, init=\"uniform\", activation=\"relu\"))\n",
    "#model.add(Dense(2))\n",
    "#model.add(Activation(\"softmax\"))\n",
    "\n",
    "from edward.models import Bernoulli, Normal\n",
    "import edward as ed\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "#N = 3072  # number of data points\n",
    "#D = 300   # number of features\n",
    "\n",
    "#z = Normal(loc=tf.zeros([N, D]), scale=tf.ones([N, D]))\n",
    "#h = Dense(768, input_dim=3072, activation='relu')(z)\n",
    "\n",
    "#x = Bernoulli(logits=Dense(2)(h))\n",
    "\n",
    "\n",
    "b = Sequential()\n",
    "#b.add(Dense(768, input_dim=3072,activation=\"relu\"))\n",
    "#b.add(Dense(384, activation=\"relu\"))\n",
    "#b.add(Dense(2))\n",
    "#b.add(Activation(\"softmax\"))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainData, testData, trainLabels, testLabels) = train_test_split(data, labels, test_size=0.25, random_state=42)\n",
    "\n",
    "def neural_network(X):\n",
    "  h = tf.tanh(tf.matmul(X, W_0) + b_0)\n",
    "  h = tf.tanh(tf.matmul(h, W_1) + b_1)\n",
    "  h = tf.matmul(h, W_2) + b_2\n",
    "  return tf.reshape(h, [-1])\n",
    "\n",
    "N = 400  # number of data points, 400 if straight from 'data'\n",
    "D = 3072   # number of features\n",
    "\n",
    "\n",
    "# MODEL\n",
    "W_0 = Normal(loc=tf.zeros([D, 10]), scale=tf.ones([D, 10]))\n",
    "W_1 = Normal(loc=tf.zeros([10, 10]), scale=tf.ones([10, 10]))\n",
    "W_2 = Normal(loc=tf.zeros([10, 1]), scale=tf.ones([10, 1]))\n",
    "b_0 = Normal(loc=tf.zeros(10), scale=tf.ones(10))\n",
    "b_1 = Normal(loc=tf.zeros(10), scale=tf.ones(10))\n",
    "b_2 = Normal(loc=tf.zeros(1), scale=tf.ones(1))\n",
    "\n",
    "X = tf.placeholder(tf.float32, [N, D])\n",
    "y = Bernoulli(logits=neural_network(X))\n",
    "\n",
    "# INFERENCE\n",
    "qW_0 = Normal(loc=tf.Variable(tf.random_normal([D, 10])),\n",
    "              scale=tf.nn.softplus(tf.Variable(tf.random_normal([D, 10]))))\n",
    "qW_1 = Normal(loc=tf.Variable(tf.random_normal([10, 10])),\n",
    "              scale=tf.nn.softplus(tf.Variable(tf.random_normal([10, 10]))))\n",
    "qW_2 = Normal(loc=tf.Variable(tf.random_normal([10, 1])),\n",
    "              scale=tf.nn.softplus(tf.Variable(tf.random_normal([10, 1]))))\n",
    "qb_0 = Normal(loc=tf.Variable(tf.random_normal([10])),\n",
    "              scale=tf.nn.softplus(tf.Variable(tf.random_normal([10]))))\n",
    "qb_1 = Normal(loc=tf.Variable(tf.random_normal([10])),\n",
    "              scale=tf.nn.softplus(tf.Variable(tf.random_normal([10]))))\n",
    "qb_2 = Normal(loc=tf.Variable(tf.random_normal([1])),\n",
    "              scale=tf.nn.softmax(tf.Variable(tf.random_normal([1]))))\n",
    "\n",
    "\n",
    "\n",
    "#type(data)\n",
    "labels = [1]*len(cats) + [0]*len(dogs)\n",
    "np.array(labels).shape\n",
    "inference = ed.KLqp({W_0: qW_0, b_0: qb_0,\n",
    "                     W_1: qW_1, b_1: qb_1,\n",
    "                     W_2: qW_2, b_2: qb_2}, data={X: data, y: labels})\n",
    "#inference = ed.MonteCarlo({W_0: qW_0, b_0: qb_0,\n",
    "#                     W_1: qW_1, b_1: qb_1,\n",
    "#                     W_2: qW_2, b_2: qb_2}, data={X: data, y: labels})\n",
    "\n",
    "\n",
    "#inference.run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'zeros_3:0' shape=(100, 10) dtype=float32>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.zeros([100, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'theano' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-3f818c0a6f65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mann_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mann_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'theano' is not defined"
     ]
    }
   ],
   "source": [
    "X, Y = data, labels\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.5)\n",
    "ann_input = theano.shared(data)\n",
    "ann_output = theano.shared(labels)\n",
    "\n",
    "# Initialize random weights between each layer\n",
    "init_1 = np.random.randn(X.shape[1], 768)\n",
    "init_2 = np.random.randn(768, 384)\n",
    "init_out = np.random.randn(384)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/theano/tensor/basic.py:2146: UserWarning: theano.tensor.round() changed its default from `half_away_from_zero` to `half_to_even` to have the same default as NumPy. Use the Theano flag `warn.round=False` to disable this warning.\n",
      "  \"theano.tensor.round() changed its default from\"\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input dimension mis-match. (input[0].shape[1] = 2, input[1].shape[1] = 400)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-463dc0dd1b5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m                        \u001b[0mact_out\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                        observed=ann_output)\n\u001b[0m\u001b[1;32m     30\u001b[0m \"\"\"\n\u001b[1;32m     31\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/pymc3/distributions/distribution.pyc\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, name, *args, **kwargs)\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'observed'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Name needs to be a string but got: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/pymc3/model.pyc\u001b[0m in \u001b[0;36mVar\u001b[0;34m(self, name, dist, data)\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m             var = ObservedRV(name=name, data=data,\n\u001b[0;32m--> 303\u001b[0;31m                              distribution=dist, model=self)\n\u001b[0m\u001b[1;32m    304\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobserved_RVs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissing_values\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/pymc3/model.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, type, owner, index, name, data, distribution, model)\u001b[0m\n\u001b[1;32m    584\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissing_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissing_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogp_elemwiset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistribution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/pymc3/distributions/discrete.pyc\u001b[0m in \u001b[0;36mlogp\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         return bound(\n\u001b[0;32m--> 162\u001b[0;31m             \u001b[0mtt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswitch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             p >= 0, p <= 1)\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/theano/gof/op.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    672\u001b[0m                 \u001b[0mthunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstorage_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m                 \u001b[0mrequired\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrequired\u001b[0m  \u001b[0;31m# We provided all inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/theano/gof/op.pyc\u001b[0m in \u001b[0;36mrval\u001b[0;34m()\u001b[0m\n\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 843\u001b[0;31m             \u001b[0mfill_storage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    844\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0mcompute_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/theano/gof/cc.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1696\u001b[0m                 \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1698\u001b[0;31m             \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/six.pyc\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input dimension mis-match. (input[0].shape[1] = 2, input[1].shape[1] = 400)"
     ]
    }
   ],
   "source": [
    "with pm.Model() as neural_network:\n",
    "    # Weights from input to hidden layer\n",
    "    weights_in_1 = pm.Normal('w_in_1', 0, sd=1, \n",
    "                             shape=(X.shape[1], 768), \n",
    "                             testval=init_1)\n",
    "    \n",
    "    # Weights from 1st to 2nd layer\n",
    "    weights_1_2 = pm.Normal('w_1_2', 0, sd=1, \n",
    "                            shape=(768, 384), \n",
    "                            testval=init_2)\n",
    "    \n",
    "    # Weights from hidden lay2er to output\n",
    "    weights_2_out = pm.Normal('w_2_out', 0, sd=1, \n",
    "                              shape=(384,), \n",
    "                              testval=init_out)\n",
    "    \n",
    "    # Build neural-network using tanh activation function\n",
    "    act_1 = T.nnet.relu(T.dot(ann_input, \n",
    "                         weights_in_1))\n",
    "    act_2 = T.nnet.relu(T.dot(act_1, \n",
    "                         weights_1_2))\n",
    "    act_out = T.nnet.sigmoid(T.dot(act_2, \n",
    "                                   weights_2_out))\n",
    "    \n",
    "    # Binary classification -> Bernoulli likelihood\n",
    "    out = pm.Bernoulli('out', \n",
    "                       act_out,\n",
    "\n",
    "                       observed=ann_output)\n",
    "\"\"\"\n",
    "model = Sequential()\n",
    "model.add(Dense(768, input_dim=3072, init=\"uniform\",\n",
    "\tactivation=\"relu\"))\n",
    "model.add(Dense(384, init=\"uniform\", activation=\"relu\"))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\"\"\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
